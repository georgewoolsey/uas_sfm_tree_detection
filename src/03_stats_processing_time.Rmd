# Statistical Analysis: Processing Time{#stats_processing_time}

In this section, we'll evaluate the influence of the processing parameters on point cloud processing time. This data was described in [this section](#ptcld_analysis).

The objective of this study is to determine the influence of different structure from motion (SfM) software (e.g. Agisoft  Metashap, OpenDroneMap, Pix4D) and processing parameters on processing time needed to create the data required for quantifying forest structure from UAS imagery. The data required includes: i) SfM-derived point cloud(s) in `.laz` or `.las` format, and ii) data extracted from these point clouds such as canopy height models (CHM), tree locations, and tree measurements (height and diameter). 

All of the predictor variables of interest in this study are categorical (a.k.a. factor or nominal) while the predicted variables are metric and include processing time (continuous > 0) and F-score (ranges from 0-1). This type of statistical analysis is described in the second edition of Kruschke's [*Doing Bayesian data analysis* (2015)](https://sites.google.com/site/doingbayesiandataanalysis/):

> This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors....Data structures of the type considered in this chapter are often encountered in real research. For example, we might want to predict monetary income from political party affiliation and religious affiliation, or we might want to predict galvanic skin response to different combinations of categories of visual stimulus and categories of auditory stimulus. As mentioned in the previous chapter, this type of data structure can arise from experiments or from observational studies. In experiments, the researcher assigns the categories (at random) to the experimental subjects. In observational studies, both the nominal predictor values and the metric predicted value are generated by processes outside the direct control of the researcher.
>
>The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. [Kruschke (2015, pp.583--584)](https://sites.google.com/site/doingbayesiandataanalysis/)

The following analysis will expand the traditional mixed ANOVA approach following the methods outlined by Kassambara in the [*Comparing Multiple Means in R*](https://www.datanovia.com/en/courses/comparing-multiple-means-in-r/) online course to build a Bayesian approach based on [Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/). This analysis was greatly enhanced by [A. Solomon Kurz's ebook supplement](https://solomonkurz.netlify.app/book/) to [Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/).

**For this example we'll use data from Agisoft Metashape only**

```{r}
ptime_data = ptcld_processing_data %>% 
  dplyr::filter(tolower(software)=="metashape")
```


## One Nominal Predictor{#one_pred_mod}

We'll start by exploring the influence of the depth map generation quality parameter on the point cloud processing time.

### Summary Statistics

Summary statistics by group:

```{r one-sum-stats}
ptime_data %>% 
  dplyr::group_by(depth_maps_generation_quality) %>% 
  dplyr::summarise(
    mean_processing_mins = mean(timer_total_time_mins, na.rm = T)
    # , med_processing_mins = median(timer_total_time_mins, na.rm = T)
    , sd_processing_mins = sd(timer_total_time_mins, na.rm = T)
    , n = dplyr::n()
  ) %>% 
  kableExtra::kbl(digits = 1, caption = "summary statistics: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

### Linear Model

We can use a linear model to obtain means by group:

```{r one-sum-lm}
lm1_temp = lm(
  timer_total_time_mins ~ 0 + depth_maps_generation_quality
  , data = ptime_data
)
# summary
lm1_temp %>% 
  broom::tidy() %>% 
  mutate(term = stringr::str_remove_all(term, "depth_maps_generation_quality")) %>% 
  kableExtra::kbl(digits = 2, caption = "linear model: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

and plot these means with 95% confidence interval

```{r}
lm1_temp %>%
  broom::tidy() %>% 
  dplyr::bind_cols(
    lm1_temp %>% 
      confint() %>% 
      dplyr::as_tibble() %>% 
      dplyr::rename(lower = 1, upper = 2)
  ) %>%
  mutate(
    term = term %>% 
      stringr::str_remove_all("depth_maps_generation_quality") %>% 
      factor(
          ordered = TRUE
          , levels = c(
            "lowest"
            , "low"
            , "medium"
            , "high"
            , "ultra high"
          )
        ) %>% forcats::fct_rev()
  ) %>% 
  ggplot(
    mapping = aes(x = term, y = estimate, fill = term)
  ) +
  geom_col() + 
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, color = "gray66") +
  scale_fill_viridis_d(option = "inferno", drop = F) +
  scale_y_continuous(breaks = scales::extended_breaks(n=8)) +
  labs(x = "depth map quality", y = "point cloud processing mins.") +
  theme_light() +
  theme(legend.position = "none", panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

### ANOVA

One-way ANOVA to test for differences in group means

```{r one-sum-aov}
aov1_temp = aov(
  timer_total_time_mins ~ 0 + depth_maps_generation_quality
  , data = ptime_data
) 
# summary
aov1_temp %>% 
  broom::tidy() %>% 
  kableExtra::kbl(digits = 2, caption = "one-way ANOVA: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

The sum of squared residuals is the same between the linear model and the ANOVA model

```{r one-sum-chk}
# RSS
identical(
  # linear model
  lm1_temp$residuals %>% 
    dplyr::as_tibble() %>% 
    mutate(value=value^2) %>% 
    dplyr::pull(value) %>% 
    sum()
  # anova
  , summary(aov1_temp)[[1]][["Sum Sq"]][[2]]
)
# F value
identical(
  # linear model
  summary(lm1_temp)$fstatistic["value"] %>% unname() %>% round(6)
  # anova
  , summary(aov1_temp)[[1]][["F value"]][[1]] %>% unname() %>% round(6)
)
```

we can use the `marginaleffects` package to [compare and contrast](https://marginaleffects.com/vignettes/comparisons.html) the mean estimates by group.

```{r}
# calculate average group effects 
contrast_temp =
  marginaleffects::avg_comparisons(
    model = lm1_temp
    , variables = list(depth_maps_generation_quality = "revpairwise")
    , comparison = "difference"
  ) %>% 
  dplyr::mutate(
    contrast = contrast %>%
      stringr::str_remove_all("mean\\(") %>% 
      stringr::str_remove_all("\\)") 
  )

# separate contrast
contrast_temp = 
  contrast_temp %>% 
  tidyr::separate_wider_delim(
    cols = contrast
    , delim = " - "
    , names = paste0(
        "sorter"
        , 1:(max(stringr::str_count(contrast_temp$contrast, "-"))+1)
      )
    , too_few = "align_start"
    , cols_remove = F
  ) %>% 
  dplyr::filter(sorter1!=sorter2) %>% 
  dplyr::mutate(
    dplyr::across(
      tidyselect::starts_with("sorter")
      , .fns = function(x){factor(
        x, ordered = T
        , levels = levels(ptime_data$depth_maps_generation_quality)
      )}
    )
    , contrast = contrast %>% forcats::fct_reorder(
        paste0(as.numeric(sorter1), as.numeric(sorter2)) %>% 
        as.numeric()
      )
    , sig_lvl = dplyr::case_when(
        p.value <= 0.01 ~ "0.01"
        , p.value <= 0.05 ~ "0.05"
        , p.value <= 0.1 ~ "0.10"
        , T ~ "not significant"
      ) %>% 
      factor(
        ordered = T
        , levels = c(
          "0.01"
          , "0.05"
          , "0.10"
          , "not significant"
        )
      )
  ) %>% 
  dplyr::arrange(contrast)

# plot
contrast_temp %>% 
  # plot
  ggplot(mapping = aes(y = contrast)) +
    geom_linerange(
      mapping = aes(xmin = conf.low, xmax = conf.high, color = sig_lvl)
      , linewidth = 5
      , alpha = 0.9
    ) +
    geom_point(mapping = aes(x = estimate)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_color_viridis_d(option = "mako", begin = 0.3, drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "Mean group constrasts"
      , color = "sig. level"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction = "horizontal"
    )
```

and view the contrasts in a table

```{r}
contrast_temp %>% 
  dplyr::arrange(contrast) %>% 
  dplyr::select(contrast, estimate, conf.low, conf.high, p.value) %>% 
  dplyr::rename(difference=estimate) %>% 
kableExtra::kbl(
    digits = 2, caption = "Mean group effects: depth map quality processing time constrasts"
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

### Bayesian{#one_pred_mod_bays}

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) notes: 

> The terminology, "analysis of variance," comes from a decomposition of overall data variance into within-group variance and between-group variance (Fisher, 1925). Algebraically, the sum of squared deviations of the scores from their overall mean equals the sum of squared deviations of the scores from their respective group means plus the sum of squared deviations of the group means from the overall mean. In other words, the total variance can be partitioned into within-group variance plus between-group variance. Because one definition of the word "analysis" is separation into constituent parts, the term ANOVA accurately describes the underlying algebra in the traditional methods. That algebraic relation is not used in the hierarchical Bayesian approach presented here. The Bayesian method can estimate component variances, however. Therefore, the Bayesian approach is not ANOVA, but is analogous to ANOVA. (p. 556)

and see section 19 from [Kurz's ebook supplement](https://bookdown.org/content/3686/metric-predicted-variable-with-one-nominal-predictor.html)

The metric predicted variable with one nominal predictor variable model has the form:

\begin{align*}
y_{i}  &\sim {\sf Normal} \bigl(\mu_{i}, \sigma_{y} \bigr) \\
\mu_{i} &= \beta_0 + \sum_{j=1}^{J} \beta_{1[j]} x_{1[j]} \bigl(i\bigr) \\
\beta_{0}  &\sim {\sf Normal} (0,10) \\ 
\beta_{1[j]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1}}) \\ 
\sigma_{\beta_{1}} &\sim {\sf uniform} (0,100) \\ 
\sigma_{y} &\sim {\sf uniform} (0,100) \\ 
\end{align*}

, where $j$ is the depth map generation quality setting corresponding to observation $i$

*to start, we'll use the default `brms::brm` prior settings which may not match those described in the model specification above* 

```{r one-sum-brms}
brms1_mod = brms::brm(
  formula = timer_total_time_mins ~ 1 + (1 | depth_maps_generation_quality)
  , data = ptime_data
  , family = brms::brmsfamily(family = "gaussian")
  , iter = 3000, warmup = 1000, chains = 4
  , cores = round(parallel::detectCores()/2)
  , file = paste0(rootdir, "/fits/brms1_mod")
)
```

check the trace plots for problems with convergence of the Markov chains

```{r}
plot(brms1_mod)
```

check the prior distributions

```{r one-sum-brms1}
# check priors
brms::prior_summary(brms1_mod) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

The `brms::brm` model summary

```{r one-sum-brms-rslt1}
brms1_mod %>% 
  brms::posterior_summary() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "parameter") %>%
  dplyr::rename_with(tolower) %>% 
  dplyr::filter(
    stringr::str_starts(parameter, "b_") 
    | stringr::str_starts(parameter, "r_") 
    | parameter == "sigma"
  ) %>%
  dplyr::mutate(
    parameter = parameter %>% 
      stringr::str_remove_all("b_depth_maps_generation_quality") %>% 
      stringr::str_remove_all("r_depth_maps_generation_quality")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "Bayesian one nominal predictor: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

With the `stats::coef` function, we can get the group-level summaries in a "non-deflection" metric. In the model, the group means represented by $\beta_{1[j]}$ are deflections from overall baseline, such that the deflections sum to zero (see [Kruschke (2015, p.554)](https://sites.google.com/site/doingbayesiandataanalysis/)). Summaries of the group-specific deflections are available via the `brms::ranef` function.

```{r one-sum-brms-rslt2}
stats::coef(brms1_mod) %>%
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "group") %>% 
  dplyr::rename_with(
    .cols = -c("group")
    , .fn = ~ stringr::str_remove_all(.x, "depth_maps_generation_quality.")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "brms::brm model: point cloud processing time by depth map quality") %>% 
  kableExtra::kable_styling()
```

We can look at the model noise standard deviation $\sigma_y$

```{r}
# extract the posterior draws
brms::as_draws_df(brms1_mod) %>% 
# plot
  ggplot(aes(x = sigma, y = 0)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21, point_size = 3
    , quantiles = 100
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(latex2exp::TeX("$\\sigma_y$")) +
  theme_light()
```

plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI)

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(brms1_mod) %>% 
  dplyr::mutate(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_quality
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    # tidybayes::stat_dotsinterval(
    #   point_interval = median_hdi, .width = .95
    #   , shape = 21, point_fill = "gray", justification = -0.04
    #   , quantiles = 100
    # ) +
    scale_fill_viridis_d(option = "inferno", drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

we can also make pairwise comparisons

```{r}
# define comparisons to make
contrast_temp = contrast_temp %>% dplyr::arrange(contrast)
contrast_list =
  1:nrow(contrast_temp) %>% 
  purrr::map(function(x){
    c(contrast_temp$sorter1[x],contrast_temp$sorter2[x])    
  }) %>% 
  list() %>%
  purrr::list_flatten()

# obtain posterior draws and calculate contrasts using tidybayes::compare_levels
brms_contrast_temp = 
  brms1_mod %>% 
    tidybayes::spread_draws(r_depth_maps_generation_quality[depth_maps_generation_quality]) %>% 
    dplyr::mutate(
      depth_maps_generation_quality = depth_maps_generation_quality %>% 
        stringr::str_replace_all("\\.", " ") %>% 
        factor(
          levels = levels(ptime_data$depth_maps_generation_quality)
          , ordered = T
        )
    ) %>% 
    dplyr::rename(value = r_depth_maps_generation_quality) %>% 
    tidybayes::compare_levels(
      value
      , by = depth_maps_generation_quality
      , comparison = 
        contrast_list
        # tidybayes::emmeans_comparison("revpairwise") 
        #"pairwise"
    ) %>%
    dplyr::mutate(
      contrast = depth_maps_generation_quality %>% 
        factor(
          levels = levels(contrast_temp$contrast)
          , ordered = T
        )
    ) 

# median_hdi summary for coloring 
brms_contrast_temp = brms_contrast_temp %>% 
  dplyr::inner_join(
    brms_contrast_temp %>% 
      dplyr::group_by(contrast) %>% 
      tidybayes::median_hdi(value, .width = c(0.5,0.95)) %>% 
      dplyr::mutate(
        sig_level = dplyr::case_when(
          .lower<0 & .upper>0 ~ 1
          , T ~ 0
        )
      ) %>% 
      dplyr::select(.width,sig_level,contrast) %>% 
      tidyr::pivot_wider(names_from = .width, values_from = sig_level) %>% 
      dplyr::mutate(
        sig_level = dplyr::case_when(
          `0.5` == 1 ~ 0
          , `0.95` == 1 ~ 1
          , T ~ 2
        ) %>% 
        factor(levels = c(0,1,2), labels = c("50%","5%","0%")) %>% 
        forcats::fct_rev()
      ) %>% 
      dplyr::select(contrast, sig_level)
    , by = dplyr::join_by(contrast)
  ) %>% 
  dplyr::group_by(contrast) %>% 
  dplyr::mutate(
    is_gt_zero = value > 0
    , pct_gt_zero = sum(is_gt_zero)/dplyr::n()
    , sig_level2 = dplyr::case_when(
      pct_gt_zero > 0.99 ~ 0
      , pct_gt_zero > 0.95 ~ 1
      , pct_gt_zero > 0.9 ~ 2
      , pct_gt_zero > 0.8 ~ 3
      , T ~ 4
    ) %>% 
    factor(levels = c(0:4), labels = c(">99%","95%","90%","80%","<80%"), ordered = T)
  )
# what?
brms_contrast_temp %>% dplyr::glimpse()
```

plot it

```{r}
# plot, finally
brms_contrast_temp %>% 
  ggplot(aes(x = value, y = contrast, fill = sig_level2)) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = c(0.5,0.95)
      # , slab_fill = "gray22", slab_alpha = 1
      , interval_color = "black", point_color = "black", point_fill = "black"
      , justification = -0.01
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_fill_viridis_d(
      option = "mako", begin = 0.3
      , drop = F
      # , labels = scales::percent
    ) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , fill = "Pr(contrast > 0)"
      , subtitle = "95% & 50% HDI of the posterior distribution of conditional mean group constrasts"
    ) +
    theme_light() +
    theme(legend.position = "top", legend.direction = "horizontal") +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

and summarize these contrasts

```{r}
# # can also use the following as substitute for the "tidybayes::spread_draws" used above to get same result
brms_contrast_temp %>% 
  dplyr::group_by(contrast) %>% 
  tidybayes::median_hdi(value) %>% 
  select(-c(.point,.interval)) %>% 
  dplyr::arrange(desc(contrast)) %>% 
  dplyr::rename(difference=value) %>% 
  kableExtra::kbl(digits = 1, caption = "brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts") %>% 
  kableExtra::kable_styling()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Two Nominal Predictors{#two_pred_mod}

Now, we'll determine the combined influence of the depth map generation quality and the depth map filtering parameters on the point cloud processing time.

### Summary Statistics

Summary statistics by group:

```{r two-sum-stats}
ptime_data %>% 
  dplyr::group_by(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  dplyr::summarise(
    mean_processing_mins = mean(timer_total_time_mins, na.rm = T)
    # , med_processing_mins = median(timer_total_time_mins, na.rm = T)
    , sd_processing_mins = sd(timer_total_time_mins, na.rm = T)
    , n = dplyr::n()
  ) %>% 
  kableExtra::kbl(
    digits = 1
    , caption = "summary statistics: point cloud processing time by depth map quality and filtering mode"
    , col.names = c(
      "depth map quality"
      , "filtering mode"
      , "mean time"
      , "sd"
      , "n"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

### Linear Model

We can use a linear model to obtain means by group:

```{r two-sum-lm}
lm2_temp = lm(
  timer_total_time_mins ~ 1 + 
    depth_maps_generation_quality + 
    depth_maps_generation_filtering_mode + 
    depth_maps_generation_quality:depth_maps_generation_filtering_mode
  , data = ptime_data
)
# summary
predict(
    lm2_temp
    , newdata = ptime_data %>% 
        dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
    , interval = "confidence"
  ) %>% 
  dplyr::as_tibble() %>% 
  dplyr::bind_cols(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::relocate(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  dplyr::arrange(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  kableExtra::kbl(
    digits = 1
    , caption = "linear model: point cloud processing time by depth map quality and filtering mode"
    , col.names = c(
      "depth map quality"
      , "filtering mode"
      , "y_hat"
      , "q2.5"
      , "q97.5"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

and plot these means with 95% confidence interval

```{r}
predict(
    lm2_temp
    , newdata = ptime_data %>% 
        dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
    , interval = "confidence"
  ) %>% 
  dplyr::as_tibble() %>% 
  dplyr::bind_cols(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode)
  ) %>% 
  ggplot(
    mapping = aes(
      y = fit
      , x = depth_maps_generation_quality
      , fill = depth_maps_generation_filtering_mode
      , group = depth_maps_generation_filtering_mode
    )
  ) +
  geom_col(width = 0.7, position = "dodge") +
  geom_errorbar(
    mapping = aes(ymin = lwr, ymax = upr)
    , width = 0.2, color = "gray66"
    , position = position_dodge(width = 0.7)
  ) +
  scale_fill_viridis_d(option = "plasma", drop = F) +
  scale_y_continuous(breaks = scales::extended_breaks(n=14)) +
  labs(
    fill = "filtering mode"
    , x = "depth map quality"
    , y = "point cloud processing mins."
  ) +
  theme_light() +
  theme(
    legend.position = "top"
    , legend.direction  = "horizontal"
  ) +
  guides(
    fill = guide_legend(override.aes = list(alpha = 0.9))
  )
```

### ANOVA

ANOVA to test for differences in group means

```{r two-sum-aov}
aov2_temp = aov(
  timer_total_time_mins ~ 1 + 
    depth_maps_generation_quality + 
    depth_maps_generation_filtering_mode + 
    depth_maps_generation_quality:depth_maps_generation_filtering_mode
  , data = ptime_data
) 
# summary
aov2_temp %>% 
  broom::tidy() %>% 
  kableExtra::kbl(digits = 2, caption = "two-way ANOVA: point cloud processing time by depth map quality and filtering mode") %>% 
  kableExtra::kable_styling()
```

We can perform pairwise comparisons of the filtering mode between at each depth map quality level

```{r}
# Pairwise comparisons between group levels
ptime_data %>%
  group_by(depth_maps_generation_quality) %>%
  rstatix::pairwise_t_test(
    timer_total_time_mins ~ depth_maps_generation_filtering_mode
    , p.adjust.method = "bonferroni"
  ) %>% 
  dplyr::select(-c(n1,p,p.signif,.y.)) %>% 
  kableExtra::kbl(
    digits = 1
    , caption = "Pairwise comparisons between filtering mode at each depth map quality group"
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

~~we can use the `emmeans` package to [perform interaction analysis](https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html) of the mean estimates using [Tukey's Honest Significant Differences method](https://search.r-project.org/R/refmans/stats/html/TukeyHSD.html).~~

we can use the `marginaleffects` package to [compare and contrast](https://marginaleffects.com/vignettes/comparisons.html) the mean estimates by group.

```{r}
# calculate average group effects 
# ... for a "cross-contrast" use cross = T (code below) where...
# ......contrasts represent the changes in adjusted predictions when 
# ......all the predictors specified in the variables argument are manipulated simultaneously
# avg_comparisons(mod, variables = c("cyl", "gear"), cross = TRUE)
contrast_temp =
  marginaleffects::avg_comparisons(
    model = lm2_temp
    , variables = list(depth_maps_generation_quality = "revpairwise")
    , comparison = "difference"
    , by = "depth_maps_generation_filtering_mode"
  ) %>% 
  dplyr::mutate(
    contrast = contrast %>%
      stringr::str_remove_all("mean\\(") %>% 
      stringr::str_remove_all("\\)") 
  )

# separate contrast
contrast_temp = contrast_temp %>% 
  dplyr::mutate(
    contrast = contrast %>% 
      stringr::str_remove_all("mean\\(") %>% 
      stringr::str_remove_all("\\)")
  ) %>% 
  tidyr::separate_wider_delim(
    cols = contrast
    , delim = " - "
    , names = paste0(
        "sorter"
        , 1:(max(stringr::str_count(contrast_temp$contrast, "-"))+1)
      )
    , too_few = "align_start"
    , cols_remove = F
  ) %>% 
  dplyr::filter(sorter1!=sorter2) %>% 
  dplyr::mutate(
    dplyr::across(
      tidyselect::starts_with("sorter")
      , .fns = function(x){factor(
        x, ordered = T
        , levels = levels(ptime_data$depth_maps_generation_quality)
      )}
    )
    , contrast = contrast %>% forcats::fct_reorder(
        paste0(as.numeric(sorter1), as.numeric(sorter2)) %>% 
        as.numeric()
      )
    , sig_lvl = dplyr::case_when(
        p.value <= 0.01 ~ "0.01"
        , p.value <= 0.05 ~ "0.05"
        , p.value <= 0.1 ~ "0.10"
        , T ~ "not significant"
      ) %>% 
      factor(
        ordered = T
        , levels = c(
          "0.01"
          , "0.05"
          , "0.10"
          , "not significant"
        )
      )
    , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %>% 
      factor(
        ordered = T
        , levels = levels(ptime_data$depth_maps_generation_filtering_mode)
      )
  ) %>% 
  dplyr::arrange(contrast, depth_maps_generation_filtering_mode)

# what?
contrast_temp %>% dplyr::ungroup() %>% dplyr::glimpse()
```

plot it

```{r}
contrast_temp %>% 
  # plot
  ggplot(mapping = aes(y = contrast)) +
    geom_linerange(
      mapping = aes(xmin = conf.low, xmax = conf.high, color = sig_lvl)
      , linewidth = 5
      , alpha = 0.9
    ) +
    geom_point(mapping = aes(x = estimate)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_color_viridis_d(option = "mako", begin = 0.3, drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "Mean group constrasts"
      , color = "sig. level"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction = "horizontal"
      , strip.text = element_text(color = "black", face = "bold")
    )
```

and view the contrasts in a table

```{r}
contrast_temp %>% 
  dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::select(contrast, depth_maps_generation_filtering_mode, estimate, conf.low, conf.high, p.value) %>% 
  dplyr::rename(difference=estimate) %>% 
kableExtra::kbl(
    digits = 2, caption = "Mean group effects: depth map quality processing time constrasts"
    , col.names = c(
      "quality contrast"
      , "filtering mode"
      , "difference (mins.)"
      , "conf.low", "conf.high", "p.value"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```


### Bayesian{#two_pred_mod_bays}

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors: 

> This chapter considers data structures that consist of a metric predicted variable and two (or more) nominal predictors....The traditional treatment of this sort of data structure is called multifactor analysis of variance (ANOVA). Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups. (pp. 583–584)

and see section 20 from [Kurz's ebook supplement](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html)

The metric predicted variable with two nominal predictor variables model has the form:

\begin{align*}
y_{i}  &\sim {\sf Normal} \bigl(\mu_{i}, \sigma_{y} \bigr) \\
\mu_{i} &= \beta_0 + \sum_{j} \beta_{1[j]} x_{1[j]} + \sum_{k} \beta_{2[k]} x_{2[k]}  + \sum_{j,k} \beta_{1\times2[j,k]} x_{1\times2[j,k]} \\
\beta_{0}  &\sim {\sf Normal} (0,100) \\ 
\beta_{1[j]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1}}) \\ 
\beta_{2[k]}  &\sim {\sf Normal} (0,\sigma_{\beta_{2}}) \\ 
\beta_{1\times2[j,k]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1\times2}}) \\ 
\sigma_{\beta_{1}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{2}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{1\times2}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{y} &\sim {\sf Cauchy} (0,109) \\ 
\end{align*}

, where $j$ is the depth map generation quality setting corresponding to observation $i$ and $k$ is the depth map filtering mode setting corresponding to observation $i$

*for this model, we'll define the priors following [Kurz](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html#implementation-in-jags-brms.-1)* who notes that:

>The noise standard deviation $\sigma_y$ is depicted in the prior statement including the argument `class = sigma`...in order to be weakly informative, we will use the half-Cauchy. Recall that since the brms default is to set the lower bound for any variance parameter to 0, there’s no need to worry about doing so ourselves. So even though the syntax only indicates `cauchy`, it’s understood to mean Cauchy with a lower bound at zero; since the mean is usually 0, that makes this a half-Cauchy...The tails of the half-Cauchy are sufficiently fat that, in practice, I’ve found it doesn’t matter much what you set the $SD$ of its prior to.

```{r}
# from Kurz: 
gamma_a_b_from_omega_sigma <- function(mode, sd) {
  if (mode <= 0) stop("mode must be > 0")
  if (sd   <= 0) stop("sd must be > 0")
  rate <- (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2)
  shape <- 1 + mode * rate
  return(list(shape = shape, rate = rate))
}

mean_y_temp <- mean(ptime_data$timer_total_time_mins)
sd_y_temp   <- sd(ptime_data$timer_total_time_mins)

omega_temp <- sd_y_temp / 2
sigma_temp <- 2 * sd_y_temp

s_r_temp <- gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp)

stanvars_temp <- 
  brms::stanvar(mean_y_temp,    name = "mean_y") + 
  brms::stanvar(sd_y_temp,      name = "sd_y") +
  brms::stanvar(s_r_temp$shape, name = "alpha") +
  brms::stanvar(s_r_temp$rate,  name = "beta")
```

Now fit the model.

```{r two-sum-brms}
brms2_mod = brms::brm(
  formula = timer_total_time_mins ~ 1 + 
    (1 | depth_maps_generation_quality) +
    (1 | depth_maps_generation_filtering_mode) + 
    (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode)
  , data = ptime_data
  , family = brms::brmsfamily(family = "gaussian")
  , iter = 4000, warmup = 2000, chains = 4
  , cores = round(parallel::detectCores()/2)
  , prior = c(
    brms::prior(normal(mean_y, sd_y * 5), class = "Intercept")
    , brms::prior(gamma(alpha, beta), class = "sd")
    , brms::prior(cauchy(0, sd_y), class = "sigma")
  )
  , stanvars = stanvars_temp
  , file = paste0(rootdir, "/fits/brms2_mod")
)
```

check the trace plots for problems with convergence of the Markov chains

```{r, fig.height=8}
plot(brms2_mod)
```

check the prior distributions

```{r two-sum-brms1}
# check priors
brms::prior_summary(brms2_mod) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

The `brms::brm` model summary

```{r two-sum-brms-rslt1}
brms2_mod %>% 
  brms::posterior_summary() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "parameter") %>%
  dplyr::rename_with(tolower) %>% 
  dplyr::filter(
    stringr::str_starts(parameter, "b_") 
    | stringr::str_starts(parameter, "r_") 
    | stringr::str_starts(parameter, "sd_") 
    | parameter == "sigma"
  ) %>%
  dplyr::mutate(
    parameter = parameter %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "Bayesian two nominal predictors: point cloud processing time by depth map quality and filtering mode") %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

We can look at the model noise standard deviation $\sigma_y$

```{r}
# extract the posterior draws
brms::as_draws_df(brms2_mod) %>% 
# plot
  ggplot(aes(x = sigma, y = 0)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21, point_size = 3
    , quantiles = 100
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(latex2exp::TeX("$\\sigma_y$")) +
  theme_light()

# how is it compared to the first model
dplyr::bind_rows(
    brms::as_draws_df(brms1_mod) %>% tidybayes::median_hdi(sigma) %>% dplyr::mutate(model = "one nominal predictor")
    , brms::as_draws_df(brms2_mod) %>% tidybayes::median_hdi(sigma) %>% dplyr::mutate(model = "two nominal predictor")
  ) %>% 
  dplyr::relocate(model) %>% 
  kableExtra::kbl(digits = 2, caption = "brms::brm model noise standard deviation comparison") %>% 
    kableExtra::kable_styling()
```

plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI)

```{r, include=FALSE, eval=FALSE}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.6
      , interval_color = "gray66", interval_alpha = 0.7
      , shape = 21, point_color = "gray66", point_fill = "black", point_alpha = 0.7
      , justification = -0.01
    ) +
    # tidybayes::stat_dotsinterval(
    #   point_interval = median_hdi, .width = .95
    #   , shape = 21, point_fill = "gray", justification = -0.04
    #   , quantiles = 100
    # ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    # facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction  = "horizontal"
    ) +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
  dplyr::rename(value = .epred) %>% 
  dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %>% forcats::fct_rev()) %>% 
  # plot
  ggplot(
    mapping = aes(
      y = value, x = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_eye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.8
      , interval_color = "black", linewidth = 1
      , point_color = "black", point_fill = "black", point_size = 1
    ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_y_continuous(breaks = scales::extended_breaks(n=10)) +
    facet_grid(cols = vars(depth_maps_generation_quality)) +
    labs(
      x = "filtering mode", y = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "none"
      , legend.direction  = "horizontal"
      , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
      , strip.text = element_text(color = "black", face = "bold")
    ) 
    # guides(
    #   fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    # )
```

we can also make pairwise comparisons

```{r}
brms_contrast_temp =
  ptime_data %>%
    dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
    tidybayes::add_epred_draws(brms2_mod, allow_new_levels = T) %>% 
    dplyr::rename(value = .epred) %>% 
    tidybayes::compare_levels(
      value
      , by = depth_maps_generation_quality
      , comparison = 
        contrast_list
        # tidybayes::emmeans_comparison("revpairwise") 
        #"pairwise"
    ) %>% 
    dplyr::rename(contrast = depth_maps_generation_quality)

# separate contrast
brms_contrast_temp = brms_contrast_temp %>% 
  dplyr::ungroup() %>% 
  tidyr::separate_wider_delim(
    cols = contrast
    , delim = " - "
    , names = paste0(
        "sorter"
        , 1:(max(stringr::str_count(brms_contrast_temp$contrast, "-"))+1)
      )
    , too_few = "align_start"
    , cols_remove = F
  ) %>% 
  dplyr::filter(sorter1!=sorter2) %>% 
  dplyr::mutate(
    dplyr::across(
      tidyselect::starts_with("sorter")
      , .fns = function(x){factor(
        x, ordered = T
        , levels = levels(ptime_data$depth_maps_generation_quality)
      )}
    )
    , contrast = contrast %>% 
      forcats::fct_reorder(
        paste0(as.numeric(sorter1), as.numeric(sorter2)) %>% 
        as.numeric()
      )
    , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %>% 
      factor(
        levels = levels(ptime_data$depth_maps_generation_filtering_mode)
        , ordered = T
      )
  ) %>% 
  # median_hdi summary for coloring 
  dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::mutate(
    is_gt_zero = value > 0
    , pct_gt_zero = sum(is_gt_zero)/dplyr::n()
    , sig_level2 = dplyr::case_when(
      pct_gt_zero > 0.99 ~ 0
      , pct_gt_zero > 0.95 ~ 1
      , pct_gt_zero > 0.9 ~ 2
      , pct_gt_zero > 0.8 ~ 3
      , T ~ 4
    ) %>% 
    factor(levels = c(0:4), labels = c(">99%","95%","90%","80%","<80%"), ordered = T)
  )

# what?
brms_contrast_temp %>% dplyr::glimpse()
```

plot it

```{r}
# plot it
brms_contrast_temp %>% 
  ggplot(
    mapping = aes(
      x = value, y = contrast
      , fill = sig_level2 # pct_gt_zero
      # , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = c(0.5,0.95)
      # , slab_fill = "gray22", slab_alpha = 1
      , interval_color = "black", point_color = "black", point_fill = "black"
      , justification = -0.01
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_fill_viridis_d(
      option = "mako", begin = 0.3
      , drop = F
      # , labels = scales::percent
    ) +
    # scale_fill_viridis_c(
    #   option = "mako", begin = 0.3, direction = -1
    #   , labels = scales::percent
    # ) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "95% & 50% HDI of the posterior distribution of conditional mean group constrasts"
      , fill = "Pr(contrast > 0)"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction  = "horizontal"
      , strip.text = element_text(color = "black", face = "bold")
    ) +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

and summarize these contrasts

```{r}
brms_contrast_temp %>%
  dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %>% 
  tidybayes::median_hdi(value) %>% 
  dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %>% 
  dplyr::rename(difference=value) %>% 
kableExtra::kbl(
    digits = 1
    , caption = "brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts"
    , col.names = c(
      "quality contrast"
      , "filtering mode"
      , "difference (mins.)"
      , "conf.low", "conf.high"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) notes that for the multiple nominal predictors model: 

> In applications with multiple levels of the factors, it is virtually always the case that we are interested in comparing particular levels with each other...These sorts of comparisons, which involve levels of a single factor and collapse across the other factor(s), are called main effect comparisons or contrasts.(p. 595)

First, let's collapse across the filtering mode to compare the depth map quality setting effect.
In a hierarchical model structure, we have to make use of the `re_formula` argument within `tidybayes::add_epred_draws`

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms2_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_quality
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    scale_fill_viridis_d(option = "inferno", drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod_bays)

```{r}
# let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod)
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms2_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::mutate(value = .epred, src = "two nominal predictor") %>%
  dplyr::bind_rows(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(brms1_mod) %>% 
      dplyr::mutate(value = .epred, src = "one nominal predictor")
  ) %>% 
  ggplot(mapping = aes(y = src, x = value, color = src, group = src)) +
  tidybayes::stat_pointinterval(position = "dodge") +
  facet_grid(rows = vars(depth_maps_generation_quality), switch = "y") +
  scale_y_discrete(NULL, breaks = NULL) +
  scale_color_viridis_d(option = "turbo", begin = 0.2, end = 0.8) +
  labs(
    y = "", x = "point cloud processing mins."
    , color = "model"
  ) +
  theme_light() +
  theme(legend.position = "top", strip.text = element_text(color = "black", face = "bold"))
  
```

these results are as expected, with [Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) noting:

> It is important to realize that the estimates of interaction contrasts are typically much more uncertain than the estimates of simple effects or main effects...This large uncertainty of an interaction contrast is caused by the fact that it involves at least four sources of uncertainty (i.e., at least four groups of data), unlike its component simple effects which each involve only half of those sources of uncertainty. In general, interaction contrasts require a lot of data to estimate accurately. (p. 598)

For completeness, let's also collapse across the depth map quality to compare the filtering mode setting effect.
In a hierarchical model structure, we have to make use of the `re_formula` argument within `tidybayes::add_epred_draws`

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms2_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "filtering mode", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

...it looks like the variation in processing time is driven by the depth map quality setting. We can quantify the variation in processing time by comparing the $\sigma$ posteriors.

```{r}
# extract the posterior draws
brms::as_draws_df(brms2_mod) %>% 
  dplyr::select(c(sigma,tidyselect::starts_with("sd_"))) %>% 
  tidyr::pivot_longer(dplyr::everything()) %>% 
  # dplyr::group_by(name) %>% 
  # tidybayes::median_hdi(value) %>% 
  dplyr::mutate(
    name = name %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering") %>% 
      forcats::fct_reorder(value)
  ) %>%
# plot
  ggplot(aes(x = value, y = name)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21 #, point_size = 3
    , quantiles = 100
  ) +
  labs(x = "", y = "") +
  theme_light()
```

Finally we can perform model selection via information criteria, from section 10 in [Kurz's ebook supplement](https://bookdown.org/content/3686/metric-predicted-variable-with-one-nominal-predictor.html):

> expected log predictive density (`elpd_loo`), the estimated effective number of parameters (`p_loo`), and the Pareto smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO; `looic`). Each estimate comes with a standard error (i.e., `SE`). Like other information criteria, the LOO values aren't of interest in and of themselves. However, the estimate of one model's LOO relative to that of another can be of great interest. We generally prefer models with lower information criteria. With the `brms::loo_compare()` function, we can compute a formal difference score between two models...The `brms::loo_compare()` output rank orders the models such that the best fitting model appears on top.

```{r}
brms1_mod = brms::add_criterion(brms1_mod, criterion = c("loo", "waic"))
brms2_mod = brms::add_criterion(brms2_mod, criterion = c("loo", "waic"))
brms::loo_compare(brms1_mod, brms2_mod, criterion = "loo")
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Two Nominal Predictors + site effects

Now, we'll add the average deflection from the baseline (i.e. the "grand mean") due to study site (i.e. the "subjects" in our data). The main effect for the study site will be added to our model with the combined influence of the depth map generation quality and the depth map filtering parameters on the point cloud processing time.

In the model we use below, the study site is modeled as a "random effect." [Hobbs et al. (2024)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1598) describe a similar model:

>It is important to understand that fitting treatment intercepts and slopes as random rather than fixed means that our inference applied to all possible sites suitable for [inclusion in the study]. In contrast, assuming fixed effects of treatment would dramatically reduce the uncertainty about those effects, but would constrain inference to the four sites that we studied. (p. 13)

From this point forward we will only show the Bayesian methodology.

### Summary Statistics

Each study site contributes one observation per depth map quality and filtering mode setting. That is, a row in the underlying data is unique by study site, depth map quality, and filtering mode.

```{r}
identical(
  # base data
  nrow(ptime_data)
  # distinct group
  , ptime_data %>% 
    dplyr::distinct(
      study_site
      , depth_maps_generation_quality
      , depth_maps_generation_filtering_mode
    ) %>% 
    nrow()
)
```

we can visualize the data using `ggplot2::geom_tile`

```{r, fig.height=8}
ptime_data %>% 
  dplyr::mutate(
    depth_maps_generation_quality = depth_maps_generation_quality %>% forcats::fct_rev()
  ) %>% 
  ggplot(mapping = aes(
    y = study_site
    , x = depth_maps_generation_filtering_mode
    , fill = log(timer_total_time_mins)
  )) +
  geom_tile(color = "white") +
  geom_text(
    mapping = aes(label = round(timer_total_time_mins)), color = "white"
    , size = 3, angle = 90
  ) +
  facet_grid(cols = vars(depth_maps_generation_quality)) + 
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_fill_viridis_c(
    option = "viridis"
    , labels = c("", "short","","", "long", "")
  ) +
  labs(
    x = "filtering mode"
    , subtitle = "depth map quality"
    , y = "study site"
    , fill = "point cloud\nprocessing time"
  ) +
  theme_light() + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
    , panel.background = element_blank()
    , panel.grid = element_blank()
    , plot.subtitle = element_text(hjust = 0.5)
    , strip.text = element_text(color = "black", face = "bold")
  )
```

### Bayesian{#3_pred_mod_bays}

[Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) describes the Hierarchical Bayesian approach to describe groups of metric data with multiple nominal predictors when every subject ("study site" in our research) contributes many measurements to each cell versus situations when each subject only contributes one observation per cell/condition: 

> When every subject contributes many measurements to every cell, then the model of the situation is a straight-forward extension of the models we have already considered. We merely add "subject" as another nominal predictor in the model, with each individual subject being a level of the predictor. If there is one predictor other than subject, the model becomes
>
> $$ y = \beta_0 + \overrightarrow \beta_1 \overrightarrow x_1 + \overrightarrow \beta_S \overrightarrow x_S + \overrightarrow \beta_{1 \times S} \overrightarrow x_{1 \times S} $$
>
> This is exactly the two-predictor model we have already considered, with the second predictor being subject. When there are two predictors other than subject, the model becomes
> 
> \begin{align*}
> y = & \; \beta_0 & \text{baseline} \\
> & + \overrightarrow \beta_1 \overrightarrow x_1 + \overrightarrow \beta_2 \overrightarrow x_2 + \overrightarrow \beta_S \overrightarrow x_S  & \text{main effects} \\
> & + \overrightarrow \beta_{1 \times 2} \overrightarrow x_{1 \times 2} + \overrightarrow \beta_{1 \times S} \overrightarrow x_{1 \times S} + \overrightarrow \beta_{2 \times S} \overrightarrow x_{2 \times S} & \text{two-way interactions} \\
> & + \overrightarrow \beta_{1 \times 2 \times S} \overrightarrow x_{1 \times 2 \times S} & \text{three-way interactions}
> \end{align*}
> 
> This model includes all the two-way interactions of the factors, plus the three-way interaction. (p. 607)

In situations in which subjects only contribute one observation per condition/cell, we simplify the model to

> \begin{align*}
> y = & \; \beta_0 \\
> & + \overrightarrow \beta_1 \overrightarrow x_1 + \overrightarrow \beta_2 \overrightarrow x_2 + \overrightarrow \beta_{1 \times 2} \overrightarrow x_{1 \times 2} \\
> & + \overrightarrow \beta_S \overrightarrow x_S
> \end{align*}

> In other words, we assume a main effect of subject, but no interaction of subject with other predictors. In this model, the subject effect (deflection) is constant across treatments, and the treatment effects (deflections) are constant across subjects. Notice that the model makes no requirement that every subject contributes a datum to every condition. Indeed, the model allows zero or multiple data per subject per condition. Bayesian estimation makes no assumptions or requirements that the design is balanced (i.e., has equal numbers of measurement in each cell). (p. 608)

and see section 20 from [Kurz's ebook supplement](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html)

*for this model, we'll define the priors following [Kurz](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html#implementation-in-jags-brms.-1)*:

```{r}
# from Kurz: 
gamma_a_b_from_omega_sigma <- function(mode, sd) {
  if (mode <= 0) stop("mode must be > 0")
  if (sd   <= 0) stop("sd must be > 0")
  rate <- (mode + sqrt(mode^2 + 4 * sd^2)) / (2 * sd^2)
  shape <- 1 + mode * rate
  return(list(shape = shape, rate = rate))
}

mean_y_temp <- mean(ptime_data$timer_total_time_mins)
sd_y_temp   <- sd(ptime_data$timer_total_time_mins)

omega_temp <- sd_y_temp / 2
sigma_temp <- 2 * sd_y_temp

s_r_temp <- gamma_a_b_from_omega_sigma(mode = omega_temp, sd = sigma_temp)

stanvars_temp <- 
  brms::stanvar(mean_y_temp,    name = "mean_y") + 
  brms::stanvar(sd_y_temp,      name = "sd_y") +
  brms::stanvar(s_r_temp$shape, name = "alpha") +
  brms::stanvar(s_r_temp$rate,  name = "beta")
```

Now fit the model.

```{r}
brms3_mod = brms::brm(
  formula = timer_total_time_mins ~ 1 + 
    (1 | depth_maps_generation_quality) +
    (1 | depth_maps_generation_filtering_mode) + 
    (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) +
    (1 | study_site)
  , data = ptime_data
  , family = brms::brmsfamily(family = "gaussian")
  , iter = 4000, warmup = 2000, chains = 4
  , cores = round(parallel::detectCores()/2)
  , prior = c(
    brms::prior(normal(mean_y, sd_y * 5), class = "Intercept")
    , brms::prior(gamma(alpha, beta), class = "sd")
    , brms::prior(cauchy(0, sd_y), class = "sigma")
  )
  , stanvars = stanvars_temp
  , file = paste0(rootdir, "/fits/brms3_mod")
)
```

check the trace plots for problems with convergence of the Markov chains

```{r, fig.height=8}
plot(brms3_mod)
```

check the prior distributions

```{r}
# check priors
brms::prior_summary(brms3_mod) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

The `brms::brm` model summary

```{r}
brms3_mod %>% 
  brms::posterior_summary() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "parameter") %>%
  dplyr::rename_with(tolower) %>% 
  dplyr::filter(
    stringr::str_starts(parameter, "b_") 
    | stringr::str_starts(parameter, "r_") 
    | stringr::str_starts(parameter, "sd_") 
    | parameter == "sigma"
  ) %>%
  dplyr::mutate(
    parameter = parameter %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "Bayesian two nominal predictors + study site effects for point cloud processing time") %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

We can look at the model noise standard deviation $\sigma_y$

```{r}
# extract the posterior draws
brms::as_draws_df(brms3_mod) %>% 
# plot
  ggplot(aes(x = sigma, y = 0)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21, point_size = 3
    , quantiles = 100
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(latex2exp::TeX("$\\sigma_y$")) +
  theme_light()

# how is it compared to our other models?
dplyr::bind_rows(
    brms::as_draws_df(brms1_mod) %>% tidybayes::median_hdi(sigma) %>% dplyr::mutate(model = "one nominal predictor")
    , brms::as_draws_df(brms2_mod) %>% tidybayes::median_hdi(sigma) %>% dplyr::mutate(model = "two nominal predictor")
    , brms::as_draws_df(brms3_mod) %>% tidybayes::median_hdi(sigma) %>% dplyr::mutate(model = "two nominal predictor + site effect")
  ) %>% 
  dplyr::relocate(model) %>% 
  kableExtra::kbl(digits = 2, caption = "brms::brm model noise standard deviation comparison") %>% 
    kableExtra::kable_styling()
```

plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI)

Note that how within `tidybayes::add_epred_draws`, we used the `re_formula` argument to average over the random effects of `study_site` (i.e., we left `(1 | study_site)` out of the formula). For this model we have to collapse across the study site effects to compare the depth map quality and filtering mode setting effects.

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms3_mod, allow_new_levels = T
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality) +
      (1 | depth_maps_generation_filtering_mode) + 
      (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %>% forcats::fct_rev()) %>% 
  # plot
  ggplot(
    mapping = aes(
      y = value, x = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_eye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.8
      , interval_color = "black", linewidth = 1
      , point_color = "black", point_fill = "black", point_size = 1
    ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_y_continuous(breaks = scales::extended_breaks(n=10)) +
    facet_grid(cols = vars(depth_maps_generation_quality)) +
    labs(
      x = "filtering mode", y = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "none"
      , legend.direction  = "horizontal"
      , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
      , strip.text = element_text(color = "black", face = "bold")
    ) 
    # guides(
    #   fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    # )
```

we can also make pairwise comparisons so long as we continue using `tidybayes::add_epred_draws` with the `re_formula` argument

```{r}
brms_contrast_temp =
  ptime_data %>%
    dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
    tidybayes::add_epred_draws(
      brms3_mod, allow_new_levels = T
      # this part is crucial
      , re_formula = ~ (1 | depth_maps_generation_quality) +
        (1 | depth_maps_generation_filtering_mode) + 
        (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode)
    ) %>% 
    dplyr::rename(value = .epred) %>% 
    tidybayes::compare_levels(
      value
      , by = depth_maps_generation_quality
      , comparison = 
        contrast_list
        # tidybayes::emmeans_comparison("revpairwise") 
        #"pairwise"
    ) %>% 
    dplyr::rename(contrast = depth_maps_generation_quality)

# separate contrast
brms_contrast_temp = brms_contrast_temp %>% 
  dplyr::ungroup() %>% 
  tidyr::separate_wider_delim(
    cols = contrast
    , delim = " - "
    , names = paste0(
        "sorter"
        , 1:(max(stringr::str_count(brms_contrast_temp$contrast, "-"))+1)
      )
    , too_few = "align_start"
    , cols_remove = F
  ) %>% 
  dplyr::filter(sorter1!=sorter2) %>% 
  dplyr::mutate(
    dplyr::across(
      tidyselect::starts_with("sorter")
      , .fns = function(x){factor(
        x, ordered = T
        , levels = levels(ptime_data$depth_maps_generation_quality)
      )}
    )
    , contrast = contrast %>% 
      forcats::fct_reorder(
        paste0(as.numeric(sorter1), as.numeric(sorter2)) %>% 
        as.numeric()
      )
    , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %>% 
      factor(
        levels = levels(ptime_data$depth_maps_generation_filtering_mode)
        , ordered = T
      )
  ) %>% 
  # median_hdi summary for coloring 
  dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::mutate(
    is_gt_zero = value > 0
    , pct_gt_zero = sum(is_gt_zero)/dplyr::n()
    , sig_level2 = dplyr::case_when(
      pct_gt_zero > 0.99 ~ 0
      , pct_gt_zero > 0.95 ~ 1
      , pct_gt_zero > 0.9 ~ 2
      , pct_gt_zero > 0.8 ~ 3
      , T ~ 4
    ) %>% 
    factor(levels = c(0:4), labels = c(">99%","95%","90%","80%","<80%"), ordered = T)
  )

# what?
brms_contrast_temp %>% dplyr::glimpse()
```

plot it

```{r}
# plot it
brms_contrast_temp %>% 
  ggplot(
    mapping = aes(
      x = value, y = contrast
      , fill = sig_level2 # pct_gt_zero
      # , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = c(0.5,0.95)
      # , slab_fill = "gray22", slab_alpha = 1
      , interval_color = "black", point_color = "black", point_fill = "black"
      , justification = -0.01
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
    scale_fill_viridis_d(
      option = "mako", begin = 0.3
      , drop = F
      # , labels = scales::percent
    ) +
    # scale_fill_viridis_c(
    #   option = "mako", begin = 0.3, direction = -1
    #   , labels = scales::percent
    # ) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "95% & 50% HDI of the posterior distribution of conditional mean group constrasts"
      , fill = "Pr(contrast > 0)"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction  = "horizontal"
      , strip.text = element_text(color = "black", face = "bold")
    ) +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

and summarize these contrasts

```{r}
brms_contrast_temp %>%
  dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %>% 
  tidybayes::median_hdi(value) %>% 
  dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %>% 
  dplyr::rename(difference=value) %>% 
kableExtra::kbl(
    digits = 1
    , caption = "brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts"
    , col.names = c(
      "quality contrast"
      , "filtering mode"
      , "difference (mins.)"
      , "conf.low", "conf.high"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

let's collapse across the filtering mode and study site to compare the depth map quality setting effect.
In a hierarchical model structure, we have to make use of the `re_formula` argument within `tidybayes::add_epred_draws`

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms3_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_quality
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    scale_fill_viridis_d(option = "inferno", drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod_bays) and [two nominal predictor model without site effects above](#two_pred_mod_bays)

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms3_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::mutate(value = .epred, src = "site+two nominal predictor") %>%
  dplyr::bind_rows(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(
        brms2_mod
        # this part is crucial
        , re_formula = ~ (1 | depth_maps_generation_quality)
      ) %>% 
      dplyr::mutate(value = .epred, src = "two nominal predictor")
    , ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(brms1_mod) %>% 
      dplyr::mutate(value = .epred, src = "one nominal predictor")
  ) %>% 
  ggplot(mapping = aes(y = src, x = value, color = src, group = src)) +
  tidybayes::stat_pointinterval(position = "dodge") +
  facet_grid(rows = vars(depth_maps_generation_quality), switch = "y") +
  scale_y_discrete(NULL, breaks = NULL) +
  # scale_color_viridis_d(option = "turbo", begin = 0.2, end = 0.8) +
  scale_color_manual(values = viridis::turbo(n = 4, begin = 0.2, end = 0.8)[c(1,3:4)]) +
  labs(
    y = "", x = "point cloud processing mins."
    , color = "model"
  ) +
  theme_light() +
  theme(legend.position = "top", strip.text = element_text(color = "black", face = "bold"))
  
```

For completeness, let's also collapse across the depth map quality to compare the filtering mode setting effect.
In a hierarchical model structure, we have to make use of the `re_formula` argument within `tidybayes::add_epred_draws`

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms3_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = .95
      , interval_color = "gray66"
      , shape = 21, point_color = "gray66", point_fill = "black"
      , justification = -0.01
    ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_x_continuous(breaks = scales::extended_breaks(n=8)) +
    labs(
      y = "filtering mode", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none")
```

let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod_bays) and [two nominal predictor model without site effects above](#two_pred_mod_bays)

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms3_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::mutate(value = .epred, src = "site+two nominal predictor") %>%
  dplyr::bind_rows(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
      tidybayes::add_epred_draws(
        brms2_mod
        # this part is crucial
        , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
      ) %>% 
      dplyr::mutate(value = .epred, src = "two nominal predictor")
  ) %>% 
  ggplot(mapping = aes(y = src, x = value, color = src, group = src)) +
  tidybayes::stat_pointinterval(position = "dodge") +
  facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = "y") +
  scale_y_discrete(NULL, breaks = NULL) +
  scale_color_manual(values = viridis::turbo(n=4, begin = 0.2, end = 0.8)[3:4]) +
  labs(
    y = "filtering mode", x = "point cloud processing mins."
    , color = "model"
  ) +
  theme_light() +
  theme(legend.position = "top", strip.text = element_text(color = "black", face = "bold"))
  
```

Finally, we can quantify the variation in processing time by comparing the $\sigma$ posteriors.

```{r}
# extract the posterior draws
brms::as_draws_df(brms3_mod) %>% 
  dplyr::select(c(sigma,tidyselect::starts_with("sd_"))) %>% 
  tidyr::pivot_longer(dplyr::everything()) %>% 
  # dplyr::group_by(name) %>% 
  # tidybayes::median_hdi(value) %>% 
  dplyr::mutate(
    name = name %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering") %>% 
      forcats::fct_reorder(value)
  ) %>%
# plot
  ggplot(aes(x = value, y = name)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21 #, point_size = 3
    , quantiles = 100
  ) +
  labs(x = "", y = "") +
  theme_light()
```

and perform model selection via information criteria with the `brms::loo_compare()` function

```{r}
brms3_mod = brms::add_criterion(brms3_mod, criterion = c("loo", "waic"))
brms::loo_compare(brms1_mod, brms2_mod, brms3_mod, criterion = "loo")
# brms::model_weights(brms1_mod, brms2_mod, brms3_mod) %>% round(3)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Gamma: Two Nominal Predictors + site effects

To this point, we have been modelling point cloud processing time presuming a Gaussian likelihood. However, the gamma likelihood more accurately represents the processing time data which is continuous and strictly positive (i.e. it is impossible to have a negative runtime). The gamma distribution is a great alternative that accounts for data with a zero lower limit and any right skew.

We borrow here from the excellent series on causal inference by [A. Solomon Kurz](https://solomonkurz.netlify.app/blog/2023-05-14-causal-inference-with-gamma-regression-or-the-problem-is-with-the-link-function-not-the-likelihood/)

### Summary Statistics

let's check our underlying data for point cloud processing time (our dependent or $y$ variable)

```{r}
# distribution
ptime_data %>% 
  ggplot(mapping = aes(x = timer_total_time_mins)) + 
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  geom_density(fill = "lightblue", alpha = 0.7, color = NA) +
  labs(y="",x="point cloud processing mins.") +
  scale_y_continuous(breaks = c(0)) +
  theme_light() +
  theme(panel.grid = element_blank())
```

and the summary statistics

```{r}
ptime_data$timer_total_time_mins %>% 
  summary()
```

### Bayesian{#4_pred_mod_bays}

With the gamma likelihood our model becomes:

*Need to check our prior selection...just go with `brms` defaults for now*

\begin{align*}
y_{i}  &\sim {\sf Gamma} \bigl(\mu_{i}, \alpha \bigr) \\
log(\mu_{i}) &= \beta_0 + \sum_{j} \beta_{1[j]} x_{1[j]} + \sum_{k} \beta_{2[k]} x_{2[k]}  + \sum_{j,k} \beta_{1\times2[j,k]} x_{1\times2[j,k]} + \sum_{s} \beta_{3[s]} x_{3[s]} \\
\beta_{0}  &\sim {\sf Normal} (0,100) \\ 
\beta_{1[j]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1}}) \\ 
\beta_{2[k]}  &\sim {\sf Normal} (0,\sigma_{\beta_{2}}) \\ 
\beta_{1\times2[j,k]}  &\sim {\sf Normal} (0,\sigma_{\beta_{1\times2}}) \\ 
\beta_{3[s]}  &\sim {\sf Normal} (0,\sigma_{\beta_{3}}) \\ 
\sigma_{\beta_{1}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{2}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{1\times2}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\sigma_{\beta_{3}} &\sim {\sf Gamma} (1.28,0.005) \\ 
\alpha &\sim {\sf Gamma} (0.01,0.01) \\ 
\end{align*}

Note that the ${\sf Gamma}$ likelihood is parameterized in terms of the mean ($\mu$) and the shape ($\alpha$)

Now fit the model.

```{r}
brms4_mod = brms::brm(
  formula = timer_total_time_mins ~ 1 + 
    (1 | depth_maps_generation_quality) +
    (1 | depth_maps_generation_filtering_mode) + 
    (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode) +
    (1 | study_site)
  , data = ptime_data
  , family = brms::brmsfamily("Gamma", link = "log") # Gamma(link = "log")
  , iter = 4000, warmup = 2000, chains = 4
  , cores = round(parallel::detectCores()/2)
  # , prior = c(
  #   brms::prior(normal(mean_y, sd_y * 5), class = "Intercept")
  #   , brms::prior(gamma(alpha, beta), class = "sd")
  #   , brms::prior(cauchy(0, sd_y), class = "sigma")
  # )
  # , stanvars = stanvars_temp
  , file = paste0(rootdir, "/fits/brms4_mod")
)
```

check the trace plots for problems with convergence of the Markov chains

```{r, fig.height=8}
plot(brms4_mod)
```

posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data

```{r}
# posterior predictive check
brms::pp_check(
    brms4_mod
    , type = "dens_overlay"
    , ndraws = 50
  ) + 
  labs(subtitle = "posterior-predictive check (overlaid densities)") +
  theme_light() +
  theme(legend.position = "top", legend.direction = "horizontal", legend.text = element_text(size = 14))
```

How’d we do capturing the conditional means and standard deviations by depth map generation quality?

```{r}
# means
p1_temp = brms::pp_check(
    brms4_mod
    , type = "stat_grouped" # "dens_overlay_grouped"
    , stat = "mean"
    , group = "depth_maps_generation_quality"
  ) + 
  scale_y_continuous(NULL, breaks = c(NULL)) +
  labs(subtitle = "means") +
  facet_grid(cols = vars(group), scales = "free") +
  theme_light()
# sds
p2_temp = brms::pp_check(
    brms4_mod
    , type = "stat_grouped" # "dens_overlay_grouped"
    , stat = "sd"
    , group = "depth_maps_generation_quality"
  ) + 
  scale_y_continuous(NULL, breaks = c(NULL)) +
  labs(subtitle = "sd's") +
  facet_grid(cols = vars(group), scales = "free") +
  theme_light()
# combine 
(p1_temp / p2_temp) &
  theme(legend.position = "none") &
  plot_annotation(
    title = "Posterior-predictive statistical checks\nby depth map quality"
    , subtitle = expression(
      "The dark blue lines are "*italic(T(y))*", and the light blue bars are for "*italic(T)(italic(y)[rep])*".")
  )
```

The means are decent, the sd's are terrible...see the section "Heterogeneous variances and robustness against outliers" in [Kruschke (2015)](https://sites.google.com/site/doingbayesiandataanalysis/) on p.602 and in  [Kurz's ebook companion](https://bookdown.org/content/3686/metric-predicted-variable-with-multiple-nominal-predictors.html#heterogeneous-variances-and-robustness-against-outliers-1)

check the prior distributions

```{r}
# check priors
brms::prior_summary(brms4_mod) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

The `brms::brm` model summary

```{r}
brms4_mod %>% 
  brms::posterior_summary() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column(var = "parameter") %>%
  dplyr::rename_with(tolower) %>% 
  dplyr::filter(
    stringr::str_starts(parameter, "b_") 
    | stringr::str_starts(parameter, "r_") 
    | stringr::str_starts(parameter, "sd_") 
    | parameter == "shape"
  ) %>%
  dplyr::mutate(
    parameter = parameter %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering")
  ) %>% 
  kableExtra::kbl(digits = 2, caption = "Bayesian two nominal predictors + study site effects for point cloud processing time") %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

We can look at the model noise standard deviation (shape) $\alpha$

```{r}
# extract the posterior draws
brms::as_draws_df(brms4_mod) %>% 
# plot
  ggplot(aes(x = shape, y = 0)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21, point_size = 3
    , quantiles = 100
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(latex2exp::TeX("$\\alpha$")) +
  theme_light()

```

plot the posterior distributions of the conditional means with the median processing time and the 95% highest posterior density interval (HDI)

Note that how within `tidybayes::add_epred_draws`, we used the `re_formula` argument to average over the random effects of `study_site` (i.e., we left `(1 | study_site)` out of the formula). For this model we have to collapse across the study site effects to compare the depth map quality and filtering mode setting effects.

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms4_mod, allow_new_levels = T
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality) +
      (1 | depth_maps_generation_filtering_mode) + 
      (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  dplyr::mutate(depth_maps_generation_quality = depth_maps_generation_quality %>% forcats::fct_rev()) %>% 
  # plot
  ggplot(
    mapping = aes(
      y = value, x = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    tidybayes::stat_eye(
      point_interval = median_hdi, .width = .95
      , slab_alpha = 0.8
      , interval_color = "black", linewidth = 1
      , point_color = "black", point_fill = "black", point_size = 1
    ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_y_log10(
      labels = scales::comma_format(suffix = " mins", accuracy = 1)
      , breaks = scales::breaks_log(n = 8)
    ) +
    facet_grid(cols = vars(depth_maps_generation_quality)) +
    labs(
      x = "filtering mode", y = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
      , fill = "Filtering Mode"
    ) +
    theme_light() +
    theme(
      legend.position = "none"
      , legend.direction  = "horizontal"
      , axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
      , strip.text = element_text(color = "black", face = "bold")
    ) 
    # guides(
    #   fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    # )
```

That really tightened-up our estimates. Note that we had to use a log scale on the y axis (using `ggplot2::scale_y_log10`) and that none of our estimates for processing time are below zero.

we can also make pairwise comparisons so long as we continue using `tidybayes::add_epred_draws` with the `re_formula` argument

```{r}
brms_contrast_temp =
  ptime_data %>%
    dplyr::distinct(depth_maps_generation_quality, depth_maps_generation_filtering_mode) %>% 
    tidybayes::add_epred_draws(
      brms4_mod, allow_new_levels = T
      # this part is crucial
      , re_formula = ~ (1 | depth_maps_generation_quality) +
        (1 | depth_maps_generation_filtering_mode) + 
        (1 | depth_maps_generation_quality:depth_maps_generation_filtering_mode)
    ) %>% 
    dplyr::rename(value = .epred) %>% 
    tidybayes::compare_levels(
      value
      , by = depth_maps_generation_quality
      , comparison = 
        contrast_list
        # tidybayes::emmeans_comparison("revpairwise") 
        #"pairwise"
    ) %>% 
    dplyr::rename(contrast = depth_maps_generation_quality)

# separate contrast
brms_contrast_temp = brms_contrast_temp %>% 
  dplyr::ungroup() %>% 
  tidyr::separate_wider_delim(
    cols = contrast
    , delim = " - "
    , names = paste0(
        "sorter"
        , 1:(max(stringr::str_count(brms_contrast_temp$contrast, "-"))+1)
      )
    , too_few = "align_start"
    , cols_remove = F
  ) %>% 
  dplyr::filter(sorter1!=sorter2) %>% 
  dplyr::mutate(
    dplyr::across(
      tidyselect::starts_with("sorter")
      , .fns = function(x){factor(
        x, ordered = T
        , levels = levels(ptime_data$depth_maps_generation_quality)
      )}
    )
    , contrast = contrast %>% 
      forcats::fct_reorder(
        paste0(as.numeric(sorter1), as.numeric(sorter2)) %>% 
        as.numeric()
      )
    , depth_maps_generation_filtering_mode = depth_maps_generation_filtering_mode %>% 
      factor(
        levels = levels(ptime_data$depth_maps_generation_filtering_mode)
        , ordered = T
      )
  ) %>% 
  # median_hdi summary for coloring 
  dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::mutate(
    is_gt_zero = value > 0
    , pct_gt_zero = sum(is_gt_zero)/dplyr::n()
    , sig_level2 = dplyr::case_when(
      pct_gt_zero > 0.99 ~ 0
      , pct_gt_zero > 0.95 ~ 1
      , pct_gt_zero > 0.9 ~ 2
      , pct_gt_zero > 0.8 ~ 3
      , T ~ 4
    ) %>% 
    factor(levels = c(0:4), labels = c(">99%","95%","90%","80%","<80%"), ordered = T)
  )

# what?
brms_contrast_temp %>% dplyr::glimpse()
```

plot it with the help of `ggplot2::scale_x_log10`

```{r}
# plot it
brms_contrast_temp %>% 
  ggplot(
    mapping = aes(
      x = value, y = contrast
      , fill = sig_level2 # pct_gt_zero
      # , fill = depth_maps_generation_filtering_mode
    )
  ) +
    # # for kicks and giggles we'll throw in the ROPE
    geom_vline(xintercept = 0.1, linetype = "dashed", color = "gray44", lwd = 1) +
    tidybayes::stat_halfeye(
      point_interval = median_hdi, .width = c(0.5,0.95)
      # , slab_fill = "gray22", slab_alpha = 1
      , interval_color = "black", point_color = "black", point_fill = "black"
      , justification = -0.01
    ) +
    scale_fill_viridis_d(
      option = "mako", begin = 0.3
      , drop = F
      # , labels = scales::percent
    ) +
    # scale_fill_viridis_c(
    #   option = "mako", begin = 0.3, direction = -1
    #   , labels = scales::percent
    # ) +
    scale_x_log10(
      labels = scales::comma_format(suffix = " mins", accuracy = 1)
      , breaks = c(0.1,1,3,10,30,100,300,800)
        # scales::breaks_log(n = 8)
    ) +
    facet_grid(cols = vars(depth_maps_generation_filtering_mode)) +
    labs(
      y = "depth map quality"
      , x = "constrast (mins.)"
      , subtitle = "95% & 50% HDI of the posterior distribution of conditional mean group constrasts"
      , fill = "Pr(contrast > 0)"
    ) +
    theme_light() +
    theme(
      legend.position = "top"
      , legend.direction  = "horizontal"
      , axis.text.x = element_text(angle = 45, hjust = 1)
      , strip.text = element_text(color = "black", face = "bold")
    ) +
    guides(
      fill = guide_legend(reverse = T, override.aes = list(alpha = 1, color = NA, shape = NA, lwd = NA))
    )
```

and summarize these contrasts

```{r}
brms_contrast_temp %>%
  dplyr::group_by(contrast, depth_maps_generation_filtering_mode) %>% 
  tidybayes::median_hdi(value) %>% 
  dplyr::arrange(contrast, depth_maps_generation_filtering_mode) %>% 
  dplyr::select(contrast, depth_maps_generation_filtering_mode, value, .lower, .upper) %>% 
  dplyr::rename(difference=value) %>% 
kableExtra::kbl(
    digits = 1
    , caption = "brms::brm model: 95% HDI of the posterior distribution of conditional mean group constrasts"
    , col.names = c(
      "quality contrast"
      , "filtering mode"
      , "difference (mins.)"
      , "conf.low", "conf.high"
    )
  ) %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::scroll_box(height = "6in")
```

let's collapse across the filtering mode and study site to compare the depth map quality setting effect.
In a hierarchical model structure, we have to make use of the `re_formula` argument within `tidybayes::add_epred_draws`

we continue to use `ggplot2::scale_x_log10`

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms4_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_quality
      , fill = depth_maps_generation_quality
    )
  ) +
    geom_vline(xintercept = 0.1, linetype = "dashed", color = "gray44", lwd = 1) +
    tidybayes::stat_dotsinterval(quantiles = 100) +
    # tidybayes::stat_halfeye(
    #   point_interval = median_hdi, .width = .95
    #   , interval_color = "gray66"
    #   , shape = 21, point_color = "gray66", point_fill = "black"
    #   , justification = -0.01
    # ) +
    scale_fill_viridis_d(option = "inferno", drop = F) +
    scale_x_log10(
      labels = scales::comma_format(suffix = " mins", accuracy = 1)
      , breaks = c(0.1,1,3,10,30,100,300,1000)
    ) +
    labs(
      y = "depth map quality", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))
```

let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod_bays) and [two nominal predictor model without site effects above](#two_pred_mod_bays) and [two nominal predictor model with site effects above](#3_pred_mod_bays)

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_quality) %>% 
  tidybayes::add_epred_draws(
    brms4_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_quality)
  ) %>% 
  dplyr::mutate(value = .epred, src = "site+two nominal predictor: gamma") %>%
  dplyr::bind_rows(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(
        brms3_mod
        # this part is crucial
        , re_formula = ~ (1 | depth_maps_generation_quality)
      ) %>% 
      dplyr::mutate(value = .epred, src = "site+two nominal predictor: gauss")
    , ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(
        brms2_mod
        # this part is crucial
        , re_formula = ~ (1 | depth_maps_generation_quality)
      ) %>% 
      dplyr::mutate(value = .epred, src = "two nominal predictor")
    , ptime_data %>% 
      dplyr::distinct(depth_maps_generation_quality) %>% 
      tidybayes::add_epred_draws(brms1_mod) %>% 
      dplyr::mutate(value = .epred, src = "one nominal predictor")
  ) %>% 
  ggplot(mapping = aes(y = src, x = value, color = src, group = src)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
  tidybayes::stat_pointinterval(position = "dodge") +
  facet_grid(rows = vars(depth_maps_generation_quality), switch = "y") +
  scale_y_discrete(NULL, breaks = NULL) +
  scale_x_continuous(breaks = scales::extended_breaks(10)) +
  scale_color_viridis_d(option = "turbo", begin = 0.2, end = 0.8) +
  labs(
    y = "", x = "point cloud processing mins."
    , color = "model"
  ) +
  theme_light() +
  theme(
    legend.position = "top", strip.text = element_text(color = "black", face = "bold")
  ) +
  guides(
    color = guide_legend(
      nrow = 2, byrow = T
      , override.aes = list(shape = 15, size = 10, lwd = NA)
    )
  )
```

Notice that our gamma likelihood model constrains the processing time estimate to strictly positive values while the other models which utilized a Gaussian likelihood predict nonsensical negative processing times. The gamma distribution also does a nice job representing the right-skew observed in the processing time data.

Let's check the posterior distribution for the overall grand mean $\beta_{0}$ to see how well the right-skew is represented (we also saw this in our posterior predictive checks). We'll make use of `brms::fixef` and we use the $exp()$ to transform the predicted values because we are using the log link with the gamma likelihood

```{r}
# we can make use of brms::fixef
brms::fixef(brms4_mod, summary = F) %>% 
  dplyr::as_tibble() %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(value = exp(Intercept)) %>%
  # plot
  ggplot(aes(x = value, y = 0)) +
    geom_vline(xintercept = 0) +
    tidybayes::stat_dotsinterval(
      point_interval = median_hdi, .width = .95
      , justification = -0.04
      , shape = 21, point_size = 3
      , quantiles = 100
    ) +
    labs(y="",x="point cloud processing mins.", subtitle = latex2exp::TeX("gamma likelihood model posterior distribution of the grand mean $\\beta_0$")) +
    scale_y_continuous(NULL, breaks = NULL) +
    scale_x_continuous(breaks = scales::extended_breaks(15)) +
    theme_light()
```

and get the summary statistics of the grand mean using `brms::as_draws_df` and `posterior::summarise_draws`

```{r}
brms::as_draws_df(brms4_mod) %>% 
  select(b_Intercept) %>% 
  dplyr::mutate(b_Intercept = exp(b_Intercept)) %>% 
  posterior::summarise_draws() %>% 
  kableExtra::kbl(digits = 1, caption = "brms::brm model: summary statiscits of the grand mean") %>% 
  kableExtra::kable_styling()
```

For completeness, let's also collapse across the depth map quality to compare the filtering mode setting effect.
In a hierarchical model structure, we have to make use of the `re_formula` argument within `tidybayes::add_epred_draws`

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms4_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::rename(value = .epred) %>% 
  # plot
  ggplot(
    mapping = aes(
      x = value, y = depth_maps_generation_filtering_mode
      , fill = depth_maps_generation_filtering_mode
    )
  ) +
    geom_vline(xintercept = 0.1, linetype = "dashed", color = "gray44", lwd = 1) +
    tidybayes::stat_dotsinterval(quantiles = 100) +
    # tidybayes::stat_halfeye(
    #   point_interval = median_hdi, .width = .95
    #   , interval_color = "gray66"
    #   , shape = 21, point_color = "gray66", point_fill = "black"
    #   , justification = -0.01
    # ) +
    scale_fill_viridis_d(option = "plasma", drop = F) +
    scale_x_log10(
      labels = scales::comma_format(suffix = " mins", accuracy = 1)
      , breaks = c(0.1,1,3,10,30,100,300,1000)
    ) +
    labs(
      y = "filtering mode", x = "point cloud processing mins."
      , subtitle = "posterior distribution of conditional means with 95% HDI"
    ) +
    theme_light() +
    theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))
```

let's compare these results to the results from our [one nominal predictor model above](#one_pred_mod_bays) and [two nominal predictor model without site effects above](#two_pred_mod_bays) and [two nominal predictor model with site effects above](#3_pred_mod_bays)

```{r}
ptime_data %>% 
  dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
  tidybayes::add_epred_draws(
    brms4_mod
    # this part is crucial
    , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
  ) %>% 
  dplyr::mutate(value = .epred, src = "site+two nominal predictor: gamma") %>%
  dplyr::bind_rows(
    ptime_data %>% 
      dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
      tidybayes::add_epred_draws(
        brms3_mod
        # this part is crucial
        , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
      ) %>% 
      dplyr::mutate(value = .epred, src = "site+two nominal predictor: gauss")
    , ptime_data %>% 
      dplyr::distinct(depth_maps_generation_filtering_mode) %>% 
      tidybayes::add_epred_draws(
        brms2_mod
        # this part is crucial
        , re_formula = ~ (1 | depth_maps_generation_filtering_mode)
      ) %>% 
      dplyr::mutate(value = .epred, src = "two nominal predictor")
  ) %>% 
  ggplot(mapping = aes(y = src, x = value, color = src, group = src)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray44") +
  tidybayes::stat_pointinterval(position = "dodge") +
  facet_grid(rows = vars(depth_maps_generation_filtering_mode), switch = "y") +
  scale_y_discrete(NULL, breaks = NULL) +
  scale_x_continuous(breaks = scales::extended_breaks(10)) +
  scale_color_manual(values = viridis::turbo(n = 4, begin = 0.2, end = 0.8)[c(2:4)]) +
  labs(
    y = "", x = "point cloud processing mins."
    , color = "model"
  ) +
  theme_light() +
  theme(
    legend.position = "top", strip.text = element_text(color = "black", face = "bold")
  ) +
  guides(
    color = guide_legend(
      nrow = 2, byrow = T
      , override.aes = list(shape = 15, size = 10, lwd = NA)
    )
  )
```

Finally, we can quantify the variation in processing time by comparing the $\sigma$ posteriors.

```{r}
# extract the posterior draws
brms::as_draws_df(brms4_mod) %>% 
  dplyr::select(c(shape,tidyselect::starts_with("sd_"))) %>% 
  tidyr::pivot_longer(dplyr::everything()) %>% 
  # dplyr::group_by(name) %>% 
  # tidybayes::median_hdi(value) %>% 
  dplyr::mutate(
    name = name %>% 
      stringr::str_replace_all("depth_maps_generation_quality", "quality") %>% 
      stringr::str_replace_all("depth_maps_generation_filtering_mode", "filtering") %>% 
      forcats::fct_reorder(value)
  ) %>%
# plot
  ggplot(aes(x = value, y = name)) +
  tidybayes::stat_dotsinterval(
    point_interval = median_hdi, .width = .95
    , justification = -0.04
    , shape = 21 #, point_size = 3
    , quantiles = 100
  ) +
  labs(x = "", y = "") +
  theme_light()
```

and perform model selection via information criteria with the `brms::loo_compare()` function

```{r}
brms4_mod = brms::add_criterion(brms4_mod, criterion = c("loo", "waic"))
brms::loo_compare(brms1_mod, brms2_mod, brms3_mod, brms4_mod, criterion = "loo")
# brms::model_weights(brms1_mod, brms2_mod, brms3_mod, brms4_mod) %>% round(3)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

```{r one-sum-norm, eval=FALSE, include=FALSE}
brms1_mod %>% 
  plot(variable = c("^b_", "sigma"), regex = TRUE)

brms::as_draws_df(
        brms1_mod
        , variable = c("^b_", "shape")
        , regex = TRUE
      ) %>% 
      # quick way to get a table of summary statistics and diagnostics
      posterior::summarize_draws(
        "mean", "median", "sd"
        ,  ~quantile(.x, probs = c(
          0.05, 0.95
          # , 0.025, 0.975
        ))
        , "rhat"
      )


# Check normality assumption by groups. Computing Shapiro-Wilk test for each group level. If the data is normally distributed, the p-value should be greater than 0.05.

ptime_data %>% 
  dplyr::group_by(depth_maps_generation_quality) %>% 
  rstatix::shapiro_test(timer_total_time_mins) %>% 
  kableExtra::kbl(digits = 3) %>% 
  kableExtra::kable_styling()

# The time is not normally distributed (p < 0.05) for most groups as assessed by Shapiro-Wilk’s test of normality. 
# 
# If you have doubt about the normality of the data, you can use the Kruskal-Wallis test, which is the non-parametric alternative to one-way ANOVA test.
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
remove(ptime_data)
gc()
```
